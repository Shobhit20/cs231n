{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 32, 32, 3)\n",
      "Training labels shape:  (50000,)\n",
      "Test data shape:  (10000, 32, 32, 3)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "cifar10_dir = 'datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (50000, 3072)\n",
      "Test data shape:  (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing: reshape the image data into rows\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "\n",
    "\n",
    "# As a sanity check, print out the shapes of the data\n",
    "print ('Training data shape: ', X_train.shape)\n",
    "print ('Test data shape: ', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second: subtract the mean image from train and test data\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(0)\n",
    "feats = {}\n",
    "feats['Weight1'] = np.random.randn(input_size, hidden_size)*0.00001\n",
    "feats['bias1'] = np.zeros(hidden_size)\n",
    "feats['Weight2'] = np.random.randn(hidden_size, num_classes)*0.00001\n",
    "feats['bias2'] = np.zeros(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_calc(features, X, y, reg):\n",
    "    W1, b1, W2, b2 = features['Weight1'],features['bias1'], features['Weight2'], features['bias2']\n",
    "    z1 = X.dot(W1) + b1 \n",
    "    loss=0.0\n",
    "    relu = np.maximum(0, z1) # pass through ReLU activation function\n",
    "    scores = relu.dot(W2) + b2\n",
    "    expscore = np.exp(scores)\n",
    "    sum = np.sum(expscore, axis=1, keepdims=True)\n",
    "    p = expscore/sum\n",
    "    prob = -np.log(p[np.arange(X.shape[0]), y])\n",
    "    loss += np.sum(prob) / X.shape[0]\n",
    "    regularization_loss = 0.5 * reg * np.sum(W1 * W1) + 0.5*reg*np.sum(W2*W2)\n",
    "    loss += regularization_loss\n",
    "    dscores = p\n",
    "    N = X.shape[0]\n",
    "    dscores[range(N),y] -= 1\n",
    "    dscores /= N\n",
    "    grads = {}\n",
    "    # W2 and b2\n",
    "    grads['W2'] = np.dot(relu.T, dscores)\n",
    "    grads['b2'] = np.sum(dscores, axis=0)\n",
    "    # next backprop into hidden layer\n",
    "    dhidden = np.dot(dscores, W2.T)\n",
    "    # backprop the ReLU non-linearity\n",
    "    dhidden[relu <= 0] = 0\n",
    "    # finally into W,b\n",
    "    grads['W1'] = np.dot(X.T, dhidden)\n",
    "    grads['b1'] = np.sum(dhidden, axis=0)\n",
    "\n",
    "    # add regularization gradient contribution\n",
    "    grads['W2'] += reg * W2\n",
    "    grads['W1'] += reg * W1\n",
    "    return loss, grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, Xtr, ytr, num_iters, batch_size, learning_rate, reg):\n",
    "    num_train = Xtr.shape[0]\n",
    "    iterations = max(num_train / batch_size, 1)\n",
    "\n",
    "    loss_history = []\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "\n",
    "    for it in xrange(num_iters):\n",
    "      index = np.random.choice(np.arange(num_train), batch_size)\n",
    "      X_batch = Xtr[index]\n",
    "      y_batch = ytr[index]\n",
    "      loss, grads = loss_calc(features, X_batch, y_batch, reg)\n",
    "      features['Weight1'] += -learning_rate * grads['W1']\n",
    "      features['bias1'] += -learning_rate * grads['b1']\n",
    "      features['Weight2'] += -learning_rate * grads['W2']\n",
    "      features['bias2'] += -learning_rate * grads['b2']\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnt_feats = train(feats, X_train, y_train,\n",
    "            num_iters=10000, batch_size=200,\n",
    "            learning_rate=1e-4, reg=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features, X):\n",
    "    z1 = X.dot(features['Weight1']) + features['bias1']\n",
    "    relu = np.maximum(0, z1) # pass through ReLU activation function\n",
    "    scores = relu.dot(features['Weight2']) + features['bias2']\n",
    "    y_pred = np.argmax(scores, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(learnt_feats, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 8 8 ..., 3 5 7]\n"
     ]
    }
   ],
   "source": [
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is  48.18\n"
     ]
    }
   ],
   "source": [
    "print (\"The accuracy of the model is \",np.sum(y_pred == y_test)*100.0/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
